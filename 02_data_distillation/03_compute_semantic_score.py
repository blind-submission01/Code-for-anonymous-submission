#!/usr/bin/env python3
# coding: utf-8
"""
é‡æ–°è®¡ç®— repair_suggestion / repair_code çš„ç›¸ä¼¼åº¦ï¼š
1) å¯¹ raw_diff å…ˆåšæ³¨é‡Š/print/logger æ¸…æ´—ï¼ˆæœ¬æ–‡ä»¶å®ç°ï¼‰ã€‚
2) ç»è¿‡ better_diff.semantic_clean_unified_diff åšè¯­ä¹‰ç²¾ç®€ã€‚
3) ç»è¿‡ genCot_phrase_2 æä¾›çš„æå–/å½’ä¸€åŒ–ä¸åµŒå…¥æ‰“åˆ†é€»è¾‘ï¼Œå¾—åˆ°æ–°çš„ score1/score2ã€‚
4) æŠŠ new_diffï¼ˆæ¸…æ´—+ç²¾ç®€åçš„ diffï¼‰ä¸æ–°åˆ†æ•°å†™å› JSONLã€‚
"""

import argparse
import json
import logging
import os
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
import difflib
import re
import textwrap
import time
import requests
from typing import Optional, List, Tuple, Dict, Any
import numpy as np
import matplotlib.pyplot as plt
from reportlab.platypus import SimpleDocTemplate, Paragraph, Image
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib.pagesizes import letter
from collections import defaultdict

# =========================
# æ—¥å¿—åˆå§‹åŒ–
# =========================

logger = logging.getLogger("after_phrase2_new_score")
if not logger.handlers:
    handler = logging.StreamHandler(sys.stdout)
    handler.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s"))
    logger.addHandler(handler)
logger.setLevel(logging.DEBUG)

# ============================================================
#           better_diff.py å†…åµŒé€»è¾‘ï¼ˆè¯­ä¹‰ç²¾ç®€ + å»å™ªï¼‰
# ============================================================

def canonical_unit(unit: str) -> str:
    """
    å¯¹ä¸€ä¸ªè¯­å¥å•å…ƒåšâ€œè¯­ä¹‰å½’ä¸€åŒ–â€ï¼š
    1. ä¼˜å…ˆç”¨ ast.parse è§£æï¼Œdump æˆä¸å¸¦ä½ç½®ä¿¡æ¯çš„ AST å­—ç¬¦ä¸²
    2. å¦‚æœè§£æå¤±è´¥ï¼ˆä¸å®Œæ•´æˆ–è¯­æ³•é”™ï¼‰ï¼Œåˆ™é€€åŒ–ä¸ºâ€œå»æ‰æ‰€æœ‰ç©ºç™½â€çš„å­—ç¬¦ä¸²
    """
    code = textwrap.dedent(unit)
    try:
        return re.sub(r"\s+", "", code)
    except SyntaxError:
        # è§£æå¤±è´¥å°±é€€åŒ–ä¸ºâ€œå»ç©ºç™½â€çš„æ–‡æœ¬
        return re.sub(r"\s+", "", code)

def group_units_from_entries(entries):
    """
    å°†è‹¥å¹² (line_idx, code_line) ç»„æˆâ€œè¯­å¥çº§å•å…ƒâ€ã€‚
    - entries: [(åŸå§‹è¡Œå·, è¡Œå†…å®¹ä¸å«+-å‰ç¼€), ...]
    - é€»è¾‘ç±»ä¼¼ä¹‹å‰çš„ logical_unitsï¼Œåªæ˜¯å¸¦ä¸Šäº†æ¯ä¸ªå•å…ƒå¯¹åº”çš„è¡Œå·åˆ—è¡¨ã€‚

    è¿”å›: [(unit_text, [line_idx1, line_idx2, ...]), ...]
    """
    units = []
    buf_lines = []
    buf_idxs = []
    depth = 0

    for idx, line in entries:
        # è·³è¿‡å¼€å¤´è¿ç»­çš„ç©ºè¡Œ
        if not buf_lines and not line.strip():
            continue

        buf_lines.append(line)
        buf_idxs.append(idx)

        # ç®€å•æ‹¬å·æ·±åº¦ç»Ÿè®¡ï¼ˆå¤šè¡Œ list comp / è°ƒç”¨ä¼šåˆå¹¶æˆä¸€ä¸ªå•å…ƒï¼‰
        depth += sum(line.count(ch) for ch in "([{") \
                 - sum(line.count(ch) for ch in ")]}")

        # æ‹¬å·é—­åˆä¸”ä¸ä»¥åæ–œæ ç»­è¡Œ â†’ ç»“æŸä¸€ä¸ªå•å…ƒ
        if depth <= 0 and not line.rstrip().endswith("\\"):
            units.append(("\n".join(buf_lines), list(buf_idxs)))
            buf_lines, buf_idxs = [], []
            depth = 0

    if buf_lines:
        units.append(("\n".join(buf_lines), list(buf_idxs)))

    return units

def semantic_filter_units(old_units, new_units):
    """
    å¯¹ä¸¤ä¸ªâ€œè¯­å¥å•å…ƒåˆ—è¡¨â€åšè¯­ä¹‰ diffï¼Œå†³å®šå“ªäº›å•å…ƒéœ€è¦ä¿ç•™ã€‚
    - old_units / new_units: çº¯æ–‡æœ¬å•å…ƒåˆ—è¡¨ï¼ˆä¸å«è¡Œå·ï¼‰

    è¿”å›:
    - old_keep: [bool, ...] æ—§å•å…ƒæ˜¯å¦ä¿ç•™
    - new_keep: [bool, ...] æ–°å•å…ƒæ˜¯å¦ä¿ç•™

    é€»è¾‘åŸºæœ¬æ²¿ç”¨ä½ ä¹‹å‰çš„ semantic_diffï¼š
    - ä½¿ç”¨ canonical_unit åš AST å½’ä¸€åŒ–
    - SequenceMatcher å¯¹é½
    - æŠŠä»…ä»…æ˜¯â€œç§»åŠ¨â€çš„å•å…ƒè¯†åˆ«å‡ºæ¥å¹¶å¿½ç•¥
    """
    old_can = [canonical_unit(u) for u in old_units]
    new_can = [canonical_unit(u) for u in new_units]

    matcher = difflib.SequenceMatcher(None, old_can, new_can, autojunk=False)

    # ç¬¬ä¸€æ¬¡éå†ï¼šç»Ÿè®¡å“ªäº› canonical åŒæ—¶å‡ºç°åœ¨ delete å’Œ insert ä¸­ â†’ è§†ä¸ºâ€œç§»åŠ¨â€
    deleted_counts = {}
    inserted_counts = {}

    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        if tag in ("delete", "replace"):
            for idx in range(i1, i2):
                c = old_can[idx]
                deleted_counts[c] = deleted_counts.get(c, 0) + 1
        if tag in ("insert", "replace"):
            for idx in range(j1, j2):
                c = new_can[idx]
                inserted_counts[c] = inserted_counts.get(c, 0) + 1

    move_counts = {
        c: min(deleted_counts.get(c, 0), inserted_counts.get(c, 0))
        for c in deleted_counts
        if c in inserted_counts
    }
    deleted_remaining = dict(move_counts)
    inserted_remaining = dict(move_counts)

    # ç¬¬äºŒæ¬¡éå†ï¼šæ ¹æ® equal / delete / insert / replace + move ä¿¡æ¯ï¼Œå†³å®šä¿ç•™å“ªäº›å•å…ƒ
    old_keep = [False] * len(old_units)
    new_keep = [False] * len(new_units)

    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        if tag == "equal":
            # å®Œå…¨ç›¸åŒçš„è¯­å¥å•å…ƒ â†’ ä¸éœ€è¦å‡ºç°åœ¨ diff ä¸­
            continue

        if tag in ("delete", "replace"):
            for idx in range(i1, i2):
                c = old_can[idx]
                # å¦‚æœè¿™æ˜¯ä¸€ä¸ªâ€œç§»åŠ¨â€çš„ä¸€ç«¯ï¼Œåˆ™è·³è¿‡
                if deleted_remaining.get(c, 0) > 0:
                    deleted_remaining[c] -= 1
                    continue
                old_keep[idx] = True

        if tag in ("insert", "replace"):
            for idx in range(j1, j2):
                c = new_can[idx]
                if inserted_remaining.get(c, 0) > 0:
                    inserted_remaining[c] -= 1
                    continue
                new_keep[idx] = True

    return old_keep, new_keep

def semantic_clean_unified_diff(diff_block: str, context_window: int = 5) -> str:
    """
    å…¥å£ï¼šå•ä¸€ diff æ–‡æœ¬ï¼ˆä¸€ä¸ª hunk æˆ–ä¸€æ®µ diff å—ï¼‰
    è¦æ±‚ï¼š
    - ' ' ä¸Šä¸‹æ–‡è¡ŒåŸæ ·ä¿ç•™ï¼ˆä¸å‚ä¸å¯¹é½ã€ä¸å‚ä¸åˆ é™¤ï¼‰
    - åªå¯¹ '+' å’Œ '-' è¡Œåšâ€œè¯­ä¹‰å»é‡â€
    - åˆ é™¤è¯­ä¹‰å®Œå…¨ä¸€è‡´ / ç§»åŠ¨ / çº¯æ ¼å¼å˜åŒ–çš„éƒ¨åˆ†
    - è¾“å‡º diff æ–‡æœ¬ï¼Œè¡Œé¡ºåºä¸åŸå§‹ diff ä¸€è‡´
    """
    lines = diff_block.splitlines()

    # æ”¶é›†åˆ é™¤å’Œæ–°å¢è¡Œï¼ˆå¸¦åŸå§‹è¡Œå·ï¼‰
    removed_entries = []  # [(line_idx, content_without_minus), ...]
    added_entries = []    # [(line_idx, content_without_plus), ...]

    for i, raw in enumerate(lines):
        if not raw:
            continue
        prefix = raw[0]
        content = raw[1:] if len(raw) > 0 else ""
        if prefix == '-' and not raw.startswith('---'):
            removed_entries.append((i, content))
        elif prefix == '+' and not raw.startswith('+++'):
            added_entries.append((i, content))
        # ' ' ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œæˆ‘ä»¬åé¢ç›´æ¥åŸæ ·ä¿ç•™

    # å°†åˆ é™¤/æ–°å¢è¡Œåˆ†åˆ«åˆå¹¶æˆâ€œè¯­å¥çº§å•å…ƒâ€
    old_units_data = group_units_from_entries(removed_entries)
    new_units_data = group_units_from_entries(added_entries)

    old_units = [u for u, idxs in old_units_data]
    new_units = [u for u, idxs in new_units_data]

    # æ ¹æ®è¯­ä¹‰å†³å®šå“ªäº›å•å…ƒï¼ˆæ—§/æ–°ï¼‰éœ€è¦ä¿ç•™
    old_keep, new_keep = semantic_filter_units(old_units, new_units)

    # æŠŠéœ€è¦ä¿ç•™çš„å•å…ƒå¯¹åº”çš„â€œåŸå§‹è¡Œå·â€æ”¶é›†èµ·æ¥
    keep_removed_line_idxs = set()
    for keep_flag, (_, idxs) in zip(old_keep, old_units_data):
        if keep_flag:
            keep_removed_line_idxs.update(idxs)

    keep_added_line_idxs = set()
    for keep_flag, (_, idxs) in zip(new_keep, new_units_data):
        if keep_flag:
            keep_added_line_idxs.update(idxs)

    # æœ€ç»ˆä¿ç•™ä¸‹æ¥çš„ä¿®æ”¹è¡Œè¡Œå·é›†åˆ
    change_line_idxs = keep_removed_line_idxs | keep_added_line_idxs

    # æŒ‰åŸå§‹è¡Œé¡ºåºé‡æ–°ç»„è£… diffï¼š
    # - ä¸Šä¸‹æ–‡ ' ' è¡Œå§‹ç»ˆä¿ç•™
    # - '-' è¡Œï¼šåªæœ‰è¡Œå·åœ¨ keep_removed_line_idxs ä¸­æ‰ä¿ç•™
    # - '+' è¡Œï¼šåªæœ‰è¡Œå·åœ¨ keep_added_line_idxs ä¸­æ‰ä¿ç•™

    n = len(lines)

    # å…ˆæŒ‰â€œè¿ç»­çš„ ' ' è¡Œâ€åˆ’åˆ†ä¸Šä¸‹æ–‡å—
    keep_context_line_idxs = set()
    i = 0
    while i < n:
        raw = lines[i]
        if raw and raw[0] == ' ':
            # è¿›å…¥ä¸€ä¸ªä¸Šä¸‹æ–‡å—
            start = i
            j = i
            while j + 1 < n and lines[j + 1] and lines[j + 1][0] == ' ':
                j += 1
            end = j

            # åˆ¤æ–­è¿™ä¸ªå—æ˜¯å¦éœ€è¦ä¿ç•™
            keep_block = False
            if change_line_idxs:
                # å¦‚æœæœ‰ä»»æ„ä¿®æ”¹è¡Œ c è½åœ¨ [start - window, end + window]ï¼Œåˆ™ä¿ç•™æ•´å—
                lower = start - context_window
                upper = end + context_window
                for c in change_line_idxs:
                    if lower <= c <= upper:
                        keep_block = True
                        break

            if keep_block:
                for k in range(start, end + 1):
                    keep_context_line_idxs.add(k)

            i = end + 1
        else:
            i += 1

    # ç¬¬äºŒéï¼šæŒ‰åŸå§‹è¡Œé¡ºåºé‡æ–°ç»„è£… diff
    out_lines = []
    for i, raw in enumerate(lines):
        if not raw:
            # ç©ºè¡Œä¿æŒåŸæ ·ï¼ˆä½ ä¹Ÿå¯ä»¥æŒ‰éœ€æ±‚æ”¹æˆåªåœ¨æœ‰ä¿®æ”¹æ—¶ä¿ç•™ï¼‰
            continue
            out_lines.append(raw)
            continue

        prefix = raw[0]

        if prefix == ' ':
            if i in keep_context_line_idxs:
                out_lines.append(raw)

        elif prefix == '-':
            if i in keep_removed_line_idxs:
                out_lines.append(raw)

        elif prefix == '+':
            if i in keep_added_line_idxs:
                out_lines.append(raw)

        else:
            # å…¶ä»–å‰ç¼€ï¼ˆä¾‹å¦‚ @@ã€diff --git ç­‰ï¼‰ç›´æ¥ä¿ç•™
            out_lines.append(raw)

    return "\n".join(out_lines)

TRIPLE_QUOTE_RE = re.compile(r'("""|\'\'\')')
# æ›´å®½æ¾çš„æ—¥å¿—/æ‰“å°åŒ¹é…ï¼šæ”¯æŒ log.*ï¼Œå¤§å°å†™ä¸æ•æ„Ÿï¼Œå…è®¸è¡Œå†…å‡ºç°ï¼ˆç”¨ \b è¾¹ç•Œï¼‰
LOG_OR_PRINT_START_RE = re.compile(
    r"\b(print|logger\.\w+|logging\.\w+|log\.\w+)\s*\(",
    re.IGNORECASE,
)

def clean_diff_noise(diff_text: str) -> str:
    """
    è¾“å…¥ï¼šgit-diff æ ¼å¼å­—ç¬¦ä¸²
    è¾“å‡ºï¼šç§»é™¤æ³¨é‡Š / æ‰“å° / æ—¥å¿—åçš„ diff å­—ç¬¦ä¸²
    æ”¹åŠ¨ï¼š
    1) ä½¿ç”¨æ›´å®½æ¾çš„ LOG/PRINT æ­£åˆ™ï¼ˆå« log.*ï¼Œå¿½ç•¥å¤§å°å†™ï¼‰ã€‚
    2) æŒ‰ diff å—ï¼ˆä»ä¸€è¡Œä»¥ "diff " å¼€å¤´åˆ°ä¸‹ä¸€ä¸ª "diff " ä¹‹é—´ï¼‰åˆ†æ®µå¤„ç†ï¼Œ
       é˜²æ­¢å› æˆªæ–­å¯¼è‡´çš„å¤šè¡Œæ³¨é‡Šè¯¯åŒ¹é…æŠŠåç»­å—ä¹Ÿåˆ æ‰ã€‚
    """
    if not diff_text:
        return ""

    lines = diff_text.splitlines()

    # å…ˆæŒ‰ diff å—åˆ‡åˆ†
    blocks: List[List[str]] = []
    current: List[str] = []
    for line in lines:
        if line.startswith("diff "):
            if current:
                blocks.append(current)
            current = [line]
        else:
            if current:
                current.append(line)
            else:
                current = [line]
    if current:
        blocks.append(current)

    def _process_block(block_lines: List[str]) -> List[str]:
        out: List[str] = []
        in_log_or_print = False
        paren_depth = 0

        # ======================================================
        # é¢„æ‰«æï¼šåœ¨â€œæœ¬ block å†…â€é…å¯¹å¤šè¡Œæ³¨é‡ŠåŒºé—´ï¼Œåªåˆ èƒ½é…å¯¹ä¸Šçš„
        # ======================================================
        skip_line_idxs = set()

        i = 0
        n = len(block_lines)
        while i < n:
            raw = block_lines[i]
            if not raw:
                i += 1
                continue

            # åªåœ¨ git diff çš„ä»£ç è¡Œé‡Œè¯†åˆ«ä¸‰å¼•å·ï¼ˆ' ', '+', '-'ï¼‰
            prefix = raw[0]
            if prefix not in (" ", "+", "-"):
                i += 1
                continue

            code = raw[1:]
            body = code.lstrip()

            # å¿…é¡»æ˜¯â€œè¡Œé¦–ï¼ˆå¿½ç•¥ç¼©è¿›ï¼‰å‡ºç°ä¸‰å¼•å·â€ï¼Œæ‰è®¤ä¸ºå¯èƒ½æ˜¯å¤šè¡Œæ³¨é‡Šè¾¹ç•Œ
            m = re.match(r'^[ \t]*("""|\'\'\')', code)
            if not m:
                i += 1
                continue

            # å•è¡Œ """ ... """ï¼šç›´æ¥è®¤ä¸ºæ˜¯æ³¨é‡Šå—ï¼Œä¸¢å¼ƒè¿™ä¸€è¡Œå³å¯
            if len(TRIPLE_QUOTE_RE.findall(code)) >= 2:
                skip_line_idxs.add(i)
                i += 1
                continue

            # å¦åˆ™ï¼šå°è¯•å‘åæ‰¾åˆ°é…å¯¹çš„ç»“æŸä¸‰å¼•å·
            j = i + 1
            found_end = False
            while j < n:
                rawj = block_lines[j]
                if rawj and rawj[0] in (" ", "+", "-"):
                    codej = rawj[1:]
                    bodyj = codej.lstrip()
                    if TRIPLE_QUOTE_RE.search(bodyj):
                        found_end = True
                        break
                j += 1

            if found_end:
                # i..j æ˜¯ä¸€ä¸ªå¯é…å¯¹çš„å¤šè¡Œæ³¨é‡ŠåŒºé—´ â†’ å…¨éƒ¨è·³è¿‡ï¼ˆä½†ç»“æ„è¡Œä»ä¼šåœ¨ä¸»å¾ªç¯ä¸­ä¿ç•™ï¼‰
                for k in (range(i, j + 1)):
                    skip_line_idxs.add(k)
                i = j + 1
            else:
                # æ²¡æ‰¾åˆ°ç»“æŸ â†’ è®¤ä¸ºæ˜¯ diff æˆªæ–­æ®‹ç‰‡ï¼Œä¸åšä»»ä½•åˆ é™¤
                i += 1

        # ======================================================
        # ä¸»å¾ªç¯ï¼šæŒ‰åŸé€»è¾‘å¤„ç†ï¼Œä½†é‡åˆ° skip_line_idxs å°±è·³è¿‡
        # ======================================================
        for idx, raw in enumerate(block_lines):
            # ç©ºè¡Œä¿ç•™
            if raw == "":
                out.append(raw)
                continue

            # diff ç»“æ„è¡Œç›´æ¥ä¿ç•™
            if raw.startswith(("diff ", "index ", "@@ ", "\\ No newline at end of file")):
                out.append(raw)
                continue
            if raw.startswith("--- ") or raw.startswith("+++ "):
                out.append(raw)
                continue

            # git diff è¡Œå‰ç¼€ï¼šå¯èƒ½æ˜¯ ' ', '+', '-'
            prefix = raw[0]
            if prefix not in (" ", "+", "-"):
                out.append(raw)
                continue

            # âœ… å¦‚æœå±äºâ€œå¯é…å¯¹â€çš„å¤šè¡Œæ³¨é‡ŠåŒºé—´ â†’ è·³è¿‡
            if idx in skip_line_idxs:
                continue

            code = raw[1:]
            body = code.lstrip()

            # 2) å•è¡Œ # æ³¨é‡Šï¼ˆæ•´è¡Œä»¥ # å¼€å¤´ï¼‰
            if body.startswith("#"):
                continue

            # 3) å¤šè¡Œ print / logger / logging / log è°ƒç”¨å¤„ç†
            if in_log_or_print:
                paren_depth += code.count("(") - code.count(")")
                if paren_depth <= 0:
                    in_log_or_print = False
                continue

            if LOG_OR_PRINT_START_RE.search(body):
                in_log_or_print = True
                paren_depth = code.count("(") - code.count(")")
                if paren_depth <= 0:
                    in_log_or_print = False
                continue  # ä¸¢å¼ƒè§¦å‘è¡Œ

            # 4) å…¶ä»–æ­£å¸¸ä»£ç è¡Œä¿ç•™
            out.append(raw)

        return out

    # åˆ†å—å¤„ç†å†æ‹¼å›
    cleaned: List[str] = []
    for blk in blocks:
        cleaned.extend(_process_block(blk))

    return "\n".join(cleaned)

# è¿™ä¸ªåˆ‡åˆ†diffå—çš„å‡½æ•°åœ¨å¤šä¸ªåœ°æ–¹ç”¨åˆ°ï¼Œæå–å‡ºæ¥å¤ç”¨
def split_diff_blocks(diff_text: str) -> List[List[str]]:
    """
    å°†åŸç”Ÿ git-diff æŒ‰å—åˆ‡åˆ†ï¼š
    - æ¯ä¸ªå—ä»ä»¥ "diff " å¼€å¤´çš„è¡Œå¼€å§‹ï¼Œåˆ°ä¸‹ä¸€ä¸ª "diff " è¡Œä¹‹å‰ï¼ˆå«èµ·å§‹è¡Œï¼‰ã€‚
    - å¦‚æœæœ€å‰é¢æ²¡æœ‰ "diff " è¡Œï¼Œä¼šæŠŠå‰ç½®è¡Œå¹¶å…¥ç¬¬ä¸€å—ã€‚
    """
    if not diff_text:
        return []
    lines = diff_text.splitlines()
    blocks: List[List[str]] = []
    current: List[str] = []
    for line in lines:
        if line.startswith("diff "):
            if current:
                blocks.append(current)
            current = [line]
        else:
            if current:
                current.append(line)
            else:
                current = [line]
    if current:
        blocks.append(current)
    return blocks

def normalize_diff(diff_text: str, mode: str) -> str:
    """
    mode:
        'none'     -> return raw diff
        'noise'    -> clean_noise(block)
        'semantic' -> semantic_clean(block)
        'full'     -> clean_noise(block) -> semantic_clean(block)
    """
    if not diff_text:
        return ""

    if mode == "none":
        return diff_text

    # å®šä¹‰å—çº§åˆ«å¤„ç†å‡½æ•°
    def process_block(block_text: str) -> str:
        if mode == "noise":
            return clean_diff_noise(block_text)
        elif mode == "semantic":
            return semantic_clean_unified_diff(block_text)
        elif mode == "full":
            return semantic_clean_unified_diff(clean_diff_noise(block_text))
        else:
            raise ValueError(f"æœªçŸ¥çš„ normalize-mode: {mode}")

    # å…¬å…±é€»è¾‘ï¼šåˆ‡å— â†’ é€å—å¤„ç†
    new_blocks = []
    for block in split_diff_blocks(diff_text):
        block_text = "\n".join(block)
        new_blocks.append(process_block(block_text))

    return "\n".join(new_blocks)

# ============================================================
#           genCot_phrase_2.py å†…åµŒé€»è¾‘ï¼ˆæå– + åµŒå…¥ï¼‰
# ============================================================
### åŸå§‹è§„èŒƒåŒ–diffå—ã€patchç›¸å…³å†…å®¹çš„é€»è¾‘
def normalize_repair_code(patch: str) -> str:
    """
    ç”±äºåœ¨ç¬¬ä¸€é˜¶æ®µä¸­ï¼Œpatchåé¢çš„å†…å®¹ä½¿ç”¨äº†ç¼©è¿›4ä¸ªç©ºæ ¼çš„æ ¼å¼
    è§‚å¯Ÿlogå‘ç°æœ‰äº›patchå‰é¢å¤šäº†4ä¸ªç©ºæ ¼ï¼Œæœ‰äº›æ²¡æœ‰ï¼›æœ‰äº›æ˜¯ç›´æ¥çš„+/-ï¼Œæœ‰äº›æ˜¯+    /-
    è¿™é‡Œåšä¸€ä¸ªç®€å•çš„è§„èŒƒåŒ–ï¼Œå»æ‰å¤šä½™çš„ç¼©è¿›ï¼Œç»Ÿä¸€æˆç›´æ¥çš„+/-æ ¼å¼
    è¿™æ ·å¯ä»¥å’Œraw_diffæ›´å¥½åœ°å¯¹é½ï¼Œ
    """
    if not patch:
        return patch
    cleaned_lines: List[str] = []
    for line in patch.splitlines():
        if line.startswith("    ---") or line.startswith("    +++") or line.startswith("+++") or line.startswith("---") or line.startswith("***") or line.startswith("    ***"):
            continue
        if line.startswith("+    "):
            cleaned_lines.append("+" + line[5:])
            continue
        if line.startswith("-    "):
            cleaned_lines.append("-" + line[5:])
            continue
        if line.startswith("    "):
            cleaned_lines.append(line[4:])
            continue
        cleaned_lines.append(line)
    return "\n".join(cleaned_lines)

### è§„èŒƒåŒ–diffå—ã€patchç›¸å…³å†…å®¹
def build_rs_chunk(block_text: str) -> str:
    """
    å°†ä¸€ä¸ª diff-block è½¬æ¢æˆç”¨äº repair_suggestion çš„æ–‡æœ¬æ ¼å¼ï¼š
    
    file_path
    ### Before Change
    <removed lines>
    ### After Change
    <added lines>

    è‹¥æ­¤å—æ²¡æœ‰ä»»ä½•ä¿®æ”¹ï¼ˆæ—  + æˆ– -ï¼‰ï¼Œè¿”å› ""ï¼ˆè¡¨ç¤ºä¸¢å¼ƒæ­¤å—ï¼‰
    """

    lines = block_text.splitlines()
    file_path = None
    removed = []
    added = []

    for line in lines:
        if line.startswith("+++ b/"):
            file_path = line[6:].strip()
        elif line.startswith("--- a/"):
            file_path = line[6:].strip()
        elif line.startswith("@@"):
            continue  # hunk header ä¸éœ€è¦
        elif line.startswith("+") and not line.startswith("+++"):
            added.append(line[1:])
        elif line.startswith("-") and not line.startswith("---"):
            removed.append(line[1:])
        else:
            continue  # ä¸Šä¸‹æ–‡è¡Œå¿½ç•¥

    if not file_path:
        return ""

    # å¦‚æœæ²¡æœ‰ä»»ä½•ä¿®æ”¹å†…å®¹ï¼Œåˆ™è·³è¿‡æ­¤å—
    if not removed and not added:
        return ""
    
    out = [file_path, "### Before Change"]
    if removed:
        out.extend(removed)
    out.append("### After Change")
    if added:
        out.extend(added)

    return "\n".join(out).strip()

def build_rc_chunk(block_text: str) -> str:
    """
    å°†ä¸€ä¸ª diff-block è½¬æ¢æˆ repair_code ç”¨çš„æ ¼å¼ï¼š
    
    file_path
    @@ ...
    <context / + / - lines>
    
    è‹¥æ— ä¿®æ”¹è¿”å› ""ï¼ˆä¸¢å¼ƒï¼‰
    """

    lines = block_text.splitlines()
    file_path = None
    out = []
    has_change = False

    for line in lines:
        if line.startswith("+++ b/"):
            file_path = line[6:].strip()
        elif line.startswith("--- a/"):
            file_path = line[6:].strip()
        elif line.startswith("@@"):
            out.append(line)
        elif line.startswith("+") and not line.startswith("+++"):
            out.append(line)
            has_change = True
        elif line.startswith("-") and not line.startswith("---"):
            out.append(line)
            has_change = True
        elif line.startswith(" "):
            out.append(line)

    if not file_path:
        return ""
    if not has_change:
        return ""

    # æ–‡ä»¶è·¯å¾„ä½œä¸ºç¬¬ä¸€è¡Œ
    return file_path + "\n" + "\n".join(out)

### ç»Ÿä¸€çš„ block-aware æˆªæ–­å‡½æ•°
def truncate_chunks_by_total_len(
    chunks: List[str],
    max_len: int,
) -> List[str]:
    """
    å¯¹ chunk åˆ—è¡¨åšâ€œæ•´ä½“é¢„ç®—â€çš„å°¾éƒ¨æˆªæ–­ï¼š
    - æŒ‰é¡ºåºç´¯è®¡å­—ç¬¦æ•°
    - è¶…è¿‡ max_len åï¼š
        - å½“å‰ chunk æˆªæ–­åˆ°åˆšå¥½å‰©ä½™å­—ç¬¦æ•°
        - åç»­ chunk ä¸¢å¼ƒ
    """
    if not chunks:
        return []

    out = []
    used = 0

    for chunk in chunks:
        if used >= max_len:
            break

        remain = max_len - used
        if len(chunk) <= remain:
            out.append(chunk)
            used += len(chunk)
        else:
            # å½“å‰å—æˆªæ–­
            out.append(chunk[:remain])
            used += remain
            break

    return out
### ç»Ÿä¸€çš„æ„é€ åµŒå…¥åˆ—è¡¨
def build_diff_inputs(
    new_diff: str,
    build_mode: str,      # "legacy" | "block"
    max_len: int = 16000,
) -> Tuple[List[str], List[str]]:
    """
    è¿”å›:
        diff_for_rs_chunks: List[str]
        diff_for_rc_chunks: List[str]

    è¯­ä¹‰ä¿è¯ï¼š
    - ä¸è®º split_blocks=True/Falseï¼ŒRS/RC çš„â€œå—å†…å®¹ç»„ç»‡æ–¹å¼â€ä¸€è‡´
    - å”¯ä¸€å·®å¼‚æ˜¯æ˜¯å¦æŠŠå— join æˆä¸€ä¸ªå¤§ chunk !!
    - æˆªæ–­é‡‡ç”¨â€œæ€»é¢„ç®—é¡ºåºæˆªæ–­â€ï¼Œä¿è¯ split/non-split ä¸€è‡´
    """
    diff_text = new_diff
    blocks = split_diff_blocks(diff_text)

    rs_chunks: List[str] = []
    rc_chunks: List[str] = []

    for blk in blocks:
        blk_text = "\n".join(blk)

        rs = build_rs_chunk(blk_text)
        if rs.strip():
            rs_chunks.append(rs)

        rc = build_rc_chunk(blk_text)
        if rc.strip():
            rc_chunks.append(rc)

    # ğŸ”‘ å¯¹â€œåˆ†å—ç»“æœâ€åšæ•´ä½“é¢„ç®—æˆªæ–­
    rs_chunks = truncate_chunks_by_total_len(rs_chunks, max_len)
    rc_chunks = truncate_chunks_by_total_len(rc_chunks, max_len)

    if build_mode == "legacy":
        # æ—§ç‰ˆï¼šåˆå¹¶æˆå•ä¸ªå¤§ chunk
        rs_chunks = ["\n\n".join(rs_chunks)] if rs_chunks else []
        rc_chunks = ["\n\n".join(rc_chunks)] if rc_chunks else []

    return rs_chunks, rc_chunks

### åµŒå…¥æ¨¡å‹è°ƒç”¨
def call_siliconflow_embedding(
    inputs,
    model: str = "Qwen/Qwen3-Embedding-8B",
    encoding_format: str = "float",
    dimensions: Optional[int] = 4096,
    timeout: int = 120,
    max_retries: int = 3,
    retry_delay: float = 5.0,
) -> Optional[List[List[float]]]:
    """
    è°ƒç”¨ç¡…åŸºæµåŠ¨ /v1/embeddings æ¥å£ç”Ÿæˆæ–‡æœ¬å‘é‡ã€‚
    :param inputs: str æˆ– List[str]
    :param model: å…·ä½“åµŒå…¥æ¨¡å‹åç§°
    :param encoding_format: 'float' æˆ– 'base64'
    :param dimensions: å¯é€‰ç»´åº¦ (ä»… Qwen/Qwen3-Embedding ç³»åˆ—æ”¯æŒ)
    :param timeout: è¯·æ±‚è¶…æ—¶ç§’æ•°
    :param max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    :param retry_delay: é‡è¯•åŸºç¡€é—´éš”ç§’æ•°
    :return: List[List[float]] æˆ– None
    """
    if isinstance(inputs, str):
        input_payload = [inputs]
    elif isinstance(inputs, list):
        input_payload = inputs
    else:
        raise TypeError("inputs å¿…é¡»æ˜¯ str æˆ– List[str]")

    api_key = ""
    if not api_key:
        logger.error("ç¼ºå°‘ç¯å¢ƒå˜é‡ SILICONFLOW_API_KEY")
        return None

    url = "https://api.siliconflow.cn/v1/embeddings"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
        "Accept": "application/json",
    }
    body = {
        "model": model,
        "input": input_payload,
        "encoding_format": encoding_format,
    }
    if dimensions is not None:
        body["dimensions"] = dimensions

    last_err: Optional[Exception] = None
    for attempt in range(max_retries):
        try:
            time.sleep(0.5)  # é¿å…è¿‡å¿«è¯·æ±‚
            resp = requests.post(url, headers=headers, json=body, timeout=timeout)
            resp.raise_for_status()
            data = resp.json()
            emb_list = []
            for item in data.get("data", []):
                emb = item.get("embedding")
                if emb is None:
                    logger.warning("ç¼ºå°‘ embedding å­—æ®µ: %s", item)
                    continue
                emb_list.append(emb)
            return emb_list
        except requests.exceptions.HTTPError as e:
            resp_payload = e.response.text if e.response is not None else repr(e)
            logger.error("åµŒå…¥è¯·æ±‚ HTTP é”™è¯¯ %s: %s", getattr(e.response, "status_code", "?"), resp_payload[:300])
            last_err = e
        except requests.exceptions.RequestException as e:
            logger.error("åµŒå…¥è¯·æ±‚ç½‘ç»œé”™è¯¯: %s", repr(e))
            last_err = e
        except Exception as e:
            logger.error("åµŒå…¥è¯·æ±‚æœªçŸ¥é”™è¯¯: %s", repr(e))
            last_err = e

        sleep_sec = retry_delay * (attempt + 1)
        logger.info("åµŒå…¥è°ƒç”¨ç¬¬ %d/%d æ¬¡å¤±è´¥ï¼Œ%.1f ç§’åé‡è¯•â€¦â€¦", attempt + 1, max_retries, sleep_sec)
        time.sleep(sleep_sec)
    
    logger.error("åµŒå…¥è¯·æ±‚å¤šæ¬¡å¤±è´¥ï¼Œæ”¾å¼ƒ: %s", repr(last_err))
    return None

### ç›¸ä¼¼åº¦è®¡ç®—éƒ¨åˆ†
def cosine_similarity_np(vec1: List[float], vec2: List[float]) -> float:
    """
    ä½¿ç”¨ numpy è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ã€‚ç»´åº¦ä¸ä¸€è‡´æ—¶æŒ‰æœ€çŸ­ç»´åº¦å¯¹é½ã€‚
    """
    try:
        v1 = np.asarray(vec1, dtype=float)
        v2 = np.asarray(vec2, dtype=float)
        if v1.size == 0 or v2.size == 0:
            return 0.0
        n = min(v1.size, v2.size)
        v1 = v1[:n]
        v2 = v2[:n]
        denom = np.linalg.norm(v1) * np.linalg.norm(v2)
        if denom == 0.0:
            return 0.0
        return float(np.dot(v1, v2) / denom)
    except Exception as e:
        logger.warning("cosine_similarity_np error: %s", repr(e))
        return 0.0

def chunk_embedding_similarity(query_emb, chunk_emb_list):
    sims = []
    for emb in chunk_emb_list:
        sims.append(cosine_similarity_np(query_emb, emb))
    return sims

def compute_beta_from_range(scores: List[float]) -> float:
    """
    æ ¹æ®æå·®åŠ¨æ€è®¡ç®— beta:
        beta = 1 - 0.5 * range
    ç¡®ä¿ beta åœ¨ [0.5, 1.0]ã€‚
    """
    if not scores:
        return 1.0
    
    smin = min(scores)
    smax = max(scores)
    r = smax - smin

    beta = 1.0 - 0.5 * r
    beta = max(0.5, min(1.0, beta))  # å®‰å…¨è¾¹ç•Œ
    return beta

def softmax(x: List[float], beta: float = 1.0) -> np.ndarray:
    x = np.array(x, dtype=float) / beta
    x = x - np.max(x)
    e = np.exp(x)
    return e / e.sum()

BETA_LIST = [0.5, 0.75, 1.0, 1.5, 2.0] # å¤‡ç”¨ beta åˆ—è¡¨ï¼Œæ–¹ä¾¿çºµå‘å¯¹æ¯”
BASELINE_BETA = 1.0
def compute_scores(
    repair_suggestion: str,
    diff_for_repair_suggestion_chunks: List[str],
    repair_code: str,
    diff_for_repair_code_chunks: List[str],
    display_idx: int,
) -> Tuple[
    float,                     # score1_A
    float,                     # score2_A
    Dict[float, float],        # score1_B_dict
    Dict[float, float],        # score2_B_dict
    Dict[str, Any],            # emb_info
]:
    """
    ä½¿ç”¨ Softmax åŠ æƒçš„ diff-block ç›¸ä¼¼åº¦ã€‚
    åŒæ—¶è¿”å›æ–¹æ³• A / æ–¹æ³• B çš„åˆ†æ•°ï¼Œä»¥åŠæœ¬æ¡è®°å½•çš„ embedding ä¿¡æ¯ã€‚
    
    ç»Ÿä¸€è¿”å›ç»“æ„ï¼ˆæ— è®ºæˆåŠŸ / å¤±è´¥ï¼‰ï¼š
        - score1_A: float
        - score2_A: float
        - score1_B_dict: {beta: float}
        - score2_B_dict: {beta: float}
        - emb_info: Dict
    """
    # ---------- 0. é¢„æ„é€ ç©ºè¿”å› ----------
    zero_B_dict = {beta: 0.0 for beta in BETA_LIST}

    empty_emb_info: Dict[str, Any] = {
        "index": display_idx,
        "emb_rs": None,
        "emb_rs_chunks": [],
        "emb_rc": None,
        "emb_rc_chunks": [],
    }

    # ===== Step 1ï¼šç»„ç»‡è¾“å…¥ =====
    # è°ƒç”¨ç¡…åŸºæµåŠ¨æ—¶éœ€è¦åˆå¹¶åœ¨ä¸€ä¸ªåˆ—è¡¨ä¸­
    inputs = (
        [repair_suggestion]
        + diff_for_repair_suggestion_chunks
        + [repair_code]
        + diff_for_repair_code_chunks
    )

    # ===== Step 2ï¼šåµŒå…¥ =====
    emb_list = call_siliconflow_embedding(inputs)
    if not emb_list or len(emb_list) != len(inputs):
        logger.warning(f"[{display_idx}] è®¡ç®—åµŒå…¥å¤±è´¥ï¼Œè¿”å› 0 åˆ†")
        empty_emb_info: Dict[str, Any] = {
            "index": display_idx,
            "emb_rs": None,
            "emb_rs_chunks": [],
            "emb_rc": None,
            "emb_rc_chunks": [],
            "diff_for_rs_chunks": diff_for_repair_suggestion_chunks,
            "diff_for_rc_chunks": diff_for_repair_code_chunks,
        }
        return 0.0, 0.0, zero_B_dict, zero_B_dict, empty_emb_info

    # ===== Step 3ï¼šåˆ‡åˆ†å‘é‡ =====
    n_rs = len(diff_for_repair_suggestion_chunks)
    n_rc = len(diff_for_repair_code_chunks)

    emb_rs = emb_list[0]                        # repair_suggestion çš„å‘é‡
    emb_rs_chunks = emb_list[1 : 1 + n_rs]      # æ¯ä¸ª diff-block çš„å‘é‡

    emb_rc = emb_list[1 + n_rs]                 # repair_code çš„å‘é‡
    emb_rc_chunks = emb_list[2 + n_rs : 2 + n_rs + n_rc]

    # ===== Step 4ï¼šå—ç›¸ä¼¼åº¦ =====
    sims_rs = chunk_embedding_similarity(emb_rs, emb_rs_chunks)
    sims_rc = chunk_embedding_similarity(emb_rc, emb_rc_chunks)

    # ===== Step 5ï¼šåŠ¨æ€è®¡ç®—beta =====
    # beta_rs = compute_beta_from_range(sims_rs)
    # beta_rc = compute_beta_from_range(sims_rc)

    # ===== Step 6ï¼šSoftmax æƒé‡ =====
    w_rs_dict = {}
    w_rc_dict = {}

    for beta in BETA_LIST:
        w_rs_dict[beta] = softmax(sims_rs, beta) if sims_rs else np.array([])
        w_rc_dict[beta] = softmax(sims_rc, beta) if sims_rc else np.array([])

    # =============================================================
    #                   æ–¹æ³• Aï¼ˆä½ çš„åŸå§‹è®¡ç®—æ–¹å¼ï¼‰
    # =============================================================

    if BASELINE_BETA not in w_rs_dict:
        raise ValueError(f"BASELINE_BETA={BASELINE_BETA} ä¸åœ¨ BETA_LIST ä¸­")
    
    score1_A = float(np.sum(w_rs_dict[BASELINE_BETA] * np.array(sims_rs))) if sims_rs else 0.0
    score2_A = float(np.sum(w_rc_dict[BASELINE_BETA] * np.array(sims_rc))) if sims_rc else 0.0

    # =============================================================
    #                   æ–¹æ³• Bï¼šå‘é‡åŠ æƒå†ç®—ç›¸ä¼¼åº¦ï¼ˆå¤š betaï¼‰
    # =============================================================

    score1_B_dict = {}
    score2_B_dict = {}

    # ä¿®å¤ï¼šè‹¥æ²¡æœ‰ chunkï¼Œåˆ™è¿”å› 0
    for beta in BETA_LIST:
        w_rs = w_rs_dict[beta]
        w_rc = w_rc_dict[beta]

        # score1_B
        if emb_rs_chunks and len(w_rs) == len(emb_rs_chunks):
            V_rs = np.sum(w_rs.reshape(-1, 1) * np.asarray(emb_rs_chunks), axis=0)
            score1_B_dict[beta] = cosine_similarity_np(emb_rs, V_rs)
        else:
            score1_B_dict[beta] = 0.0

        # score2_B
        if emb_rc_chunks and len(w_rc) == len(emb_rc_chunks):
            V_rc = np.sum(w_rc.reshape(-1, 1) * np.asarray(emb_rc_chunks), axis=0)
            score2_B_dict[beta] = cosine_similarity_np(emb_rc, V_rc)
        else:
            score2_B_dict[beta] = 0.0


    # ===== Step 7ï¼šæ—¥å¿—è¾“å‡º =====
    logger.info(
        "[%s] A(score1=%.4f, score2=%.4f) | "
        "B(beta=%.2f)(score1=%.4f, score2=%.4f)",
        display_idx,
        score1_A,
        score2_A,
        BASELINE_BETA,
        score1_B_dict[BASELINE_BETA],
        score2_B_dict[BASELINE_BETA],
    )
    
    # ===== Step 8ï¼šå‡†å¤‡ embedding ä¿¡æ¯ï¼ˆå†™åˆ°å•ç‹¬æ–‡ä»¶ç”¨ï¼‰ =====
    emb_info: Dict[str, Any] = {
        "index": display_idx,
        "emb_rs": emb_rs,
        "emb_rs_chunks": emb_rs_chunks,
        "emb_rc": emb_rc,
        "emb_rc_chunks": emb_rc_chunks,
    }

    return score1_A, score2_A, score1_B_dict, score2_B_dict, emb_info

# ============================================================
#           after_phrase2_new_score.py åŸæœ‰ä¸»ä½“é€»è¾‘
# ============================================================
def compute_scores_with_retry(
    repair_suggestion: str,
    diff_for_repair_suggestion_chunks: List[str],
    normalized_repair_code: str,
    diff_for_repair_code_chunks: List[str],
    display_idx: int,
    max_retries: int = 3,
) -> Tuple[
    float,
    float,
    Dict[float, float],
    Dict[float, float],
    int,
    Dict[str, Any],
]:
    """
    è°ƒç”¨ compute_scoresï¼Œè‹¥æ‰€æœ‰åˆ†æ•°å‡ä¸º 0 åˆ™é‡è¯•ã€‚

    è¿”å›ï¼ˆå§‹ç»ˆç»“æ„ä¸€è‡´ï¼‰ï¼š
        score1_A: float
        score2_A: float
        score1_B_dict: Dict[beta, float]
        score2_B_dict: Dict[beta, float]
        attempts_used: int
        emb_info: Dict
    """
    zero_B_dict = {beta: 0.0 for beta in BETA_LIST}
    last_score1_A = 0.0
    last_score2_A = 0.0
    last_score1_B_dict = zero_B_dict
    last_score2_B_dict = zero_B_dict
    last_emb_info: Dict[str, Any] = {
        "index": display_idx,
        "emb_rs": None,
        "emb_rs_chunks": [],
        "emb_rc": None,
        "emb_rc_chunks": [],
    }

    last_err: Optional[Exception] = None
    for attempt in range(1, max_retries + 1):
        try:
            (
                score1_A,
                score2_A,
                score1_B_dict,
                score2_B_dict,
                emb_info,
            ) = compute_scores(
                repair_suggestion,
                diff_for_repair_suggestion_chunks,
                normalized_repair_code,
                diff_for_repair_code_chunks,
                display_idx,
            )
            last_score1_A = score1_A
            last_score2_A = score2_A
            last_score1_B_dict = score1_B_dict
            last_score2_B_dict = score2_B_dict
            last_emb_info = emb_info

            # ===== æˆåŠŸåˆ¤å®šï¼šä¸æ˜¯â€œå…¨ 0â€ =====
            all_zero = (
                score1_A == 0.0
                and score2_A == 0.0
                and all(v == 0.0 for v in score1_B_dict.values())
                and all(v == 0.0 for v in score2_B_dict.values())
            )

            if not all_zero:
                return (
                    score1_A,
                    score2_A,
                    score1_B_dict,
                    score2_B_dict,
                    attempt,
                    emb_info,
                )
            
        except Exception as e:
            last_err = e
            logger.exception("è®°å½• %d ç¬¬ %d æ¬¡è®¡ç®—ç›¸ä¼¼åº¦å¤±è´¥ï¼š%s", display_idx, attempt, repr(e))
            last_scores = (0.0, 0.0, 0.0, 0.0)
    if last_err:
        logger.warning("è®°å½• %d é‡è¯• %d æ¬¡åä»ä¸º 0ï¼Œæœ€åå¼‚å¸¸ï¼š%s", display_idx, max_retries, repr(last_err))
    else:
        logger.warning("è®°å½• %d é‡è¯• %d æ¬¡åä»ä¸º 0", display_idx, max_retries)

    return (
        last_score1_A,
        last_score2_A,
        last_score1_B_dict,
        last_score2_B_dict,
        max_retries,
        last_emb_info,
    )

### JSONL è¯»å†™
def read_jsonl(path: str) -> List[Dict[str, Any]]:
    out = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            out.append(json.loads(line))
    return out

def write_jsonl(path: str, items: List[Dict[str, Any]], append: bool = False) -> None:
    mode = "a" if append else "w"
    with open(path, mode, encoding="utf-8") as f:
        for obj in items:
            f.write(json.dumps(obj, ensure_ascii=False))
            f.write("\n")

### ç»˜å›¾
def plot_hist(values, title, save_path, bins=200):
    """ç»˜åˆ¶ç›´æ–¹å›¾ï¼ˆbins é»˜è®¤ 200ï¼‰"""
    if not values:
        logger.warning(f"plot_hist: æ— æ•°æ®å¯ç»˜å›¾ {title}")
        return
    
    plt.figure(figsize=(8, 5))
    plt.hist(values, bins=bins, color="steelblue", edgecolor="black", alpha=0.7)
    plt.title(title)
    plt.xlabel("score")
    plt.ylabel("count")
    plt.grid(True, linestyle="--", alpha=0.4)
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close()
    logger.info(f"ç›´æ–¹å›¾å·²ä¿å­˜åˆ°ï¼š{save_path}")

def plot_hist_overlay(
    values_a,
    values_b,
    label_a,
    label_b,
    title,
    save_path,
    bins=200,
):
    if not values_a or not values_b:
        logger.warning(f"plot_hist_overlay: æ— æ•°æ®å¯ç»˜å›¾ {title}")
        return

    plt.figure(figsize=(8, 5))

    plt.hist(
        values_a,
        bins=bins,
        alpha=0.5,
        label=label_a,
        color="steelblue",
        edgecolor="black",
    )
    plt.hist(
        values_b,
        bins=bins,
        alpha=0.5,
        label=label_b,
        color="orange",
        edgecolor="black",
    )

    plt.title(title)
    plt.xlabel("score")
    plt.ylabel("count")
    plt.legend()
    plt.grid(True, linestyle="--", alpha=0.4)
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close()

    logger.info(f"å åŠ ç›´æ–¹å›¾å·²ä¿å­˜åˆ°ï¼š{save_path}")

def plot_multi_beta_hist(beta_to_values, title, save_path, bins=200):
    if not beta_to_values:
        logger.warning(f"plot_multi_beta_hist: æ— æ•°æ® {title}")
        return

    plt.figure(figsize=(9, 6))

    colors = {
        0.5: "#1f77b4",
        0.75: "#2ca02c",
        1.0: "#ff7f0e",
        1.5: "#9467bd",
        2.0: "#d62728",
    }

    for beta, values in sorted(beta_to_values.items()):
        if not values:
            continue
        plt.hist(
            values,
            bins=bins,
            alpha=0.4,
            label=f"Î²={beta}",
            color=colors.get(beta),
            edgecolor="black",
        )

    plt.title(title)
    plt.xlabel("score")
    plt.ylabel("count")
    plt.legend()
    plt.grid(True, linestyle="--", alpha=0.4)
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close()

    logger.info(f"å¤š beta åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°ï¼š{save_path}")

def generate_pdf_report(image_paths, output_pdf):
    doc = SimpleDocTemplate(output_pdf, pagesize=letter)
    styles = getSampleStyleSheet()
    story = []

    story.append(Paragraph("Softmax Score Analysis Report", styles["Title"]))

    for img in image_paths:
        story.append(Image(img, width=500, height=400))
        story.append(Paragraph(img, styles["Normal"]))

    doc.build(story)

### å¤„ç†å•æ¡è®°å½•
def process_one_record(
    rec: Dict[str, Any],
    normalize_mode: str,
    build_mode: str,
) -> Dict[str, Any]:
    """
    å¤„ç†å•æ¡è®°å½•ã€‚

    è¿”å›å­—æ®µè¯­ä¹‰ï¼š
        - new_diff
        - new_score1_A, new_score2_A
        - new_score1_B_by_beta, new_score2_B_by_beta
        - score1_B_vs_A_improved (beta=1.0)
        - score2_B_vs_A_improved (beta=1.0)
        - attempts_used
        - embeddings
    """
    display_idx = rec.get("index") 
    raw_diff = rec.get("raw_diff", "")

    # 1) ä½¿ç”¨ normalize_diff è¿›è¡Œæ¸…æ´—+è¯­ä¹‰ç²¾ç®€
    new_diff = normalize_diff(raw_diff, normalize_mode)

    # 2) ç”Ÿæˆæ‰“åˆ†æ‰€éœ€å­—æ®µï¼ˆç»Ÿä¸€å…¥å£ï¼‰
    repair_suggestion = rec.get("repair_suggestion") or rec.get("Repair_Suggestion", "")
    repair_code = rec.get("repair_code") or rec.get("Repair_Code", "")
    normalized_repair_code = normalize_repair_code(repair_code)

    diff_for_rs_chunks, diff_for_rc_chunks = build_diff_inputs(
        new_diff=new_diff,
        build_mode=build_mode,   # "legacy" | "block"
        max_len=16000,
    )

    # 3) ç›¸ä¼¼åº¦æ‰“åˆ†ï¼ˆå«é‡è¯•ï¼‰
    (
        score1_A,
        score2_A,
        score1_B_dict,
        score2_B_dict,
        attempts_used,
        emb_info,
    ) = compute_scores_with_retry(
        repair_suggestion,
        diff_for_rs_chunks,
        normalized_repair_code,
        diff_for_rc_chunks,
        display_idx,
    )

    score1_B_baseline = score1_B_dict.get(BASELINE_BETA, 0.0)
    score2_B_baseline = score2_B_dict.get(BASELINE_BETA, 0.0)

    # B ç›¸æ¯” A æ˜¯å¦æå‡
    score1_B_vs_A_improved = score1_B_baseline > score1_A
    score2_B_vs_A_improved = score2_B_baseline > score2_A
    
    logger.info(
        "è®°å½• %d å®Œæˆ | "
        "A(score1=%.4f, score2=%.4f) | "
        "B(beta=%.1f)(score1=%.4f, score2=%.4f) | "
        "B>A: (score1=%s, score2=%s) | "
        "attempts=%d",
        display_idx,
        score1_A,
        score2_A,
        BASELINE_BETA,
        score1_B_baseline,
        score2_B_baseline,
        score1_B_vs_A_improved,
        score2_B_vs_A_improved,
        attempts_used,
    )
    
    res = dict(rec)  # ä¸æ”¹åŠ¨åŸå¯¹è±¡å¼•ç”¨
    res.update({
        "new_diff": new_diff,

        # A æ–¹æ³•ï¼ˆæ ‡é‡ï¼‰
        "new_score1_A": score1_A,
        "new_score2_A": score2_A,

        # B æ–¹æ³•ï¼ˆæŒ‰ betaï¼‰
        "new_score1_B_by_beta": score1_B_dict,
        "new_score2_B_by_beta": score2_B_dict,

        # æ¨ªå‘å¯¹æ¯”ï¼ˆbeta=1.0ï¼‰
        "score1_B_vs_A_improved": score1_B_vs_A_improved,
        "score2_B_vs_A_improved": score2_B_vs_A_improved,

        # è°ƒè¯•ä¿¡æ¯
        "attempts_used": attempts_used,

        # åµŒå…¥å‘é‡å­˜å‚¨
        "embeddings": emb_info
    })
    return res

### ä¸»å‡½æ•°å…¥å£
def main():
    parser = argparse.ArgumentParser(description="é‡æ–°è®¡ç®— score1/score2 (A/Bæ–¹æ³•) å¹¶å†™å› JSONL")
    parser.add_argument("--input", required=True, help="è¾“å…¥ JSONL æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", required=True, help="è¾“å‡º JSONL æ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "--normalize-mode",
        choices=["none", "noise", "semantic", "full"],
        default="full",
        help="diff é¢„å¤„ç†æ¨¡å¼ï¼šnone / noise / semantic / full"
    )
    parser.add_argument(
        "--build-mode",
        choices=["legacy", "block"],
        default="block",
        help="diff æ„é€ æ–¹å¼ï¼šlegacy=æ•´å—æ—§é€»è¾‘ï¼Œblock=æŒ‰ diff å—æ–°é€»è¾‘"
    )
    parser.add_argument(
        "--embed-output",
        default=None,
        help="è‹¥æŒ‡å®šï¼Œåˆ™è¾“å‡º embedding ä¿¡æ¯åˆ°æ­¤ JSONL"
    )
    parser.add_argument(
        "--plot-dir",
        default=None,
        help="è‹¥æŒ‡å®šï¼Œåˆ™åœ¨è¯¥ç›®å½•ä¸‹è¾“å‡ºåˆ†æ•°åˆ†å¸ƒ/å¢é‡çš„ç›´æ–¹å›¾",
    )
    parser.add_argument(
        "--workers",
        type=int,
        default=1,
        help="çº¿ç¨‹æ± å¤§å°",
    )
    args = parser.parse_args()

    logger.info(
    "=== normalize-mode = %s | build-mode = %s ===",
    args.normalize_mode,
    args.build_mode
)

    # ===== è¯»å–æ•°æ® =====
    records = read_jsonl(args.input)

    total = len(records)
    logger.info("è¯»å–è¾“å…¥æ–‡ä»¶ %sï¼Œè®°å½•æ•°: %d", args.input, total)

    # å…ˆæ¸…ç©ºè¾“å‡ºæ–‡ä»¶
    write_jsonl(args.output, [], append=False)
    if args.embed_output:
        write_jsonl(args.embed_output, [], append=False)

    # ===== ç»Ÿè®¡å®¹å™¨ =====
    # A æ–¹æ³•ï¼ˆæ ‡é‡ï¼‰
    score1_A_by_grp = {"all": [], "true": [], "false": []}
    score2_A_by_grp = {"all": [], "true": [], "false": []}

    # B æ–¹æ³•ï¼ˆæŒ‰ betaï¼‰
    score1_B_by_beta = {
        "all": defaultdict(list),
        "true": defaultdict(list),
        "false": defaultdict(list),
    }
    score2_B_by_beta = {
        "all": defaultdict(list),
        "true": defaultdict(list),
        "false": defaultdict(list),
    }

    # B - Aï¼ˆä»… beta=1.0ï¼‰
    diff1_BA_by_grp = {"all": [], "true": [], "false": []}
    diff2_BA_by_grp = {"all": [], "true": [], "false": []}

    # è®¡æ•°
    processed = 0
    score1_BA_improved_cnt = {"all": 0, "true": 0, "false": 0}
    score2_BA_improved_cnt = {"all": 0, "true": 0, "false": 0}

    with ThreadPoolExecutor(max_workers=args.workers) as executor:
        future_to_idx = {}
        for rec in records:
            rec_idx = rec.get("index")
            future = executor.submit(process_one_record, rec, args.normalize_mode, args.build_mode)
            future_to_idx[future] = rec_idx

        for future in as_completed(future_to_idx):
            rec_idx = future_to_idx[future]
            try:
                new_rec = future.result() # processè·å¾—çš„æ•°æ®
            except Exception as e:
                logger.exception("å­çº¿ç¨‹å¤„ç†å¼‚å¸¸ï¼ˆindex=%sï¼‰ï¼š%s", rec_idx, repr(e))
                continue

            if not isinstance(new_rec, dict):
                logger.warning("å­çº¿ç¨‹è¿”å›éå­—å…¸ç»“æœï¼ˆindex=%sï¼‰ï¼Œè·³è¿‡ï¼š%s", rec_idx, type(new_rec))
                continue

            processed += 1

            # ç«‹å³å†™å‡ºä¸»ç»“æœ è¿™è¾¹è¿˜éœ€è¦æ”¹ä¸€æ”¹
            emb_info = new_rec.pop("embeddings", None)
            write_jsonl(args.output, [new_rec], append=True)

            # å†™å‡º embedding ä¿¡æ¯
            if emb_info is not None and args.embed_output:
                write_jsonl(args.embed_output, [emb_info], append=True)

            # ===== ç»Ÿè®¡å¤„ç† =====

            grp = "true" if new_rec.get("gemini_judgement") is True else "false"

            s1A = new_rec["new_score1_A"]
            s2A = new_rec["new_score2_A"]
            s1B_by_beta = new_rec["new_score1_B_by_beta"]
            s2B_by_beta = new_rec["new_score2_B_by_beta"]

            # === A æ–¹æ³• ===
            for g in ("all", grp):
                score1_A_by_grp[g].append(s1A)
                score2_A_by_grp[g].append(s2A)
            # === B æ–¹æ³•ï¼ˆæ‰€æœ‰ betaï¼‰===
            for beta, v in s1B_by_beta.items():
                for g in ("all", grp):
                    score1_B_by_beta[g][beta].append(v)

            for beta, v in s2B_by_beta.items():
                for g in ("all", grp):
                    score2_B_by_beta[g][beta].append(v)

            # === B - Aï¼ˆbeta=BASELINE_BETAï¼‰===
            s1B_baseline = s1B_by_beta.get(BASELINE_BETA, 0.0)
            s2B_baseline = s2B_by_beta.get(BASELINE_BETA, 0.0)

            for g in ("all", grp):
                diff1_BA_by_grp[g].append(s1B_baseline - s1A)
                diff2_BA_by_grp[g].append(s2B_baseline - s2A)

            if s1B_baseline > s1A:
                for g in ("all", grp):
                    score1_BA_improved_cnt[g] += 1
            if s2B_baseline > s2A:
                for g in ("all", grp):
                    score2_BA_improved_cnt[g] += 1


    # ===== æ±‡æ€» =====
    def mean_safe(xs):
        return float(np.mean(xs)) if xs else 0.0

    logger.info("======= æ±‡æ€»ç»Ÿè®¡ =======")
    logger.info("å¤„ç†æ¡æ•°: %d / %d", processed, total)

    for g in ("all", "true", "false"):
        denom = max(len(score1_A_by_grp[g]), 1)
        logger.info(
            "[%s] mean scores | "
            "A(score1=%.4f, score2=%.4f) | "
            "B(beta=%.1f)(score1=%.4f, score2=%.4f) | "
            "B>A rate(score1=%.2f%%, score2=%.2f%%)",
            g,
            mean_safe(score1_A_by_grp[g]),
            mean_safe(score2_A_by_grp[g]),
            BASELINE_BETA,
            mean_safe(score1_B_by_beta[g][BASELINE_BETA]),
            mean_safe(score2_B_by_beta[g][BASELINE_BETA]),
            score1_BA_improved_cnt[g] / denom * 100,
            score2_BA_improved_cnt[g] / denom * 100,
        )

    # ===== å¯é€‰ç»˜å›¾ =====
    if args.plot_dir:
        os.makedirs(args.plot_dir, exist_ok=True)

        beta_tag = f"beta={BASELINE_BETA}"

        for grp in ["all", "true", "false"]:
            grp_suffix = f"gemini={grp}"

            # ---------- A vs B (baseline beta) ----------
            plot_hist_overlay(
                score1_A_by_grp[grp],
                score1_B_by_beta[grp][BASELINE_BETA],
                label_a="Method A",
                label_b=f"Method B ({beta_tag})",
                title=f"Score1 Distribution (A vs B @ {beta_tag}) | {grp_suffix}",
                save_path=f"{args.plot_dir}/score1_A_vs_B_{beta_tag}_{grp}.png",
            )

            plot_hist_overlay(
                score2_A_by_grp[grp],
                score2_B_by_beta[grp][BASELINE_BETA],
                label_a="Method A",
                label_b=f"Method B ({beta_tag})",
                title=f"Score2 Distribution (A vs B @ {beta_tag}) | {grp_suffix}",
                save_path=f"{args.plot_dir}/score2_A_vs_B_{beta_tag}_{grp}.png",
            )

            # ---------- B - A å·®å€¼ (baseline beta) ----------
            plot_hist(
                diff1_BA_by_grp[grp],
                f"Score1 Difference (B - A @ {beta_tag}) | {grp_suffix}",
                f"{args.plot_dir}/diff_score1_BA_{beta_tag}_{grp}.png",
            )

            plot_hist(
                diff2_BA_by_grp[grp],
                f"Score2 Difference (B - A @ {beta_tag}) | {grp_suffix}",
                f"{args.plot_dir}/diff_score2_BA_{beta_tag}_{grp}.png",
            )

            # ---------- Method B: multi-beta ----------
            plot_multi_beta_hist(
                score1_B_by_beta[grp],
                f"Score1 Method-B (multi beta) | {grp_suffix}",
                f"{args.plot_dir}/score1_B_multi_beta_{grp}.png",
            )

            plot_multi_beta_hist(
                score2_B_by_beta[grp],
                f"Score2 Method-B (multi beta) | {grp_suffix}",
                f"{args.plot_dir}/score2_B_multi_beta_{grp}.png",
            )

        logger.info(
            "å·²åœ¨ %s ä¸­è¾“å‡º all / true / false ä¸‰ç§è§†è§’ä¸‹çš„ A/Bã€B-Aã€multi-beta åˆ†å¸ƒå›¾ï¼ˆbaseline=%sï¼‰",
            args.plot_dir,
            BASELINE_BETA,
        )



if __name__ == "__main__":
    main()
